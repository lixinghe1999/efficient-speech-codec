{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio Codec 18.0kbps Initialized\n",
      "Quantization Vis: \n",
      "     Freq dims:  [2, 2, 4, 8, 16, 32]\n",
      "     Channel(hidden) dims:  [384, 384, 192, 96, 72, 45]\n",
      "     projections from:  [768, 768, 768, 768, 1152, 1440]\n",
      "     projections to:  [192, 192, 384, 384, 576, 720]\n",
      "     group_vq_dims:  [384, 384, 768, 768, 1152, 1440]\n"
     ]
    }
   ],
   "source": [
    "from models.codec import SwinCrossScaleCodec\n",
    "\n",
    "model = SwinCrossScaleCodec(patch_size = [3,2],\n",
    "                 swin_depth = 2,\n",
    "                 swin_heads = [3, 3, 6, 12, 24],\n",
    "                 window_size = 4,\n",
    "                 mlp_ratio = 4.,\n",
    "                 in_dim = 2, \n",
    "                 in_freq = 192, \n",
    "                 h_dims = [45, 45, 72, 96, 192, 384], \n",
    "                 max_streams = 6, \n",
    "                 proj = [4,4,2,2,2,2], \n",
    "                 overlap = 2, \n",
    "                 num_vqs = 6, \n",
    "                 codebook_size = 1024, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torch\n",
    "audio_path = \"../swin-debug-vis/test/spanish_instance1.wav\"\n",
    "model.eval()\n",
    "x, sr = torchaudio.load(audio_path)\n",
    "x = x[:, :-80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1, 160000-80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 192, 2000])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.ft(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "outputs = model.train_one_step(x, None, streams=6)\n",
    "\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "   test_outputs =  model.test_one_step(x, None, streams=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 192, 2000])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_outputs[\"recon_feat\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchaudio/functional/functional.py:576: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (17) may be set too low.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchaudio/functional/functional.py:576: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (33) may be set too low.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchaudio/functional/functional.py:576: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (65) may be set too low.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchaudio/functional/functional.py:576: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (64) may be set too high. Or, the value for `n_freqs` (129) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from models.losses import TimeLoss, FreqLoss\n",
    "recon_loss = TimeLoss()\n",
    "mel_loss = FreqLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.randn(1,47920)\n",
    "x_ = torch.randn(1,47920)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0037)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recon_loss(x, x_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12.3666)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel_loss(x, x_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class Convolution1D(nn.Conv1d):\n",
    "    \"\"\"1D Convolution (dilated-causal convolution)\"\"\"\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size,\n",
    "                 stride=1,\n",
    "                 padding=1,\n",
    "                 dilation=1,\n",
    "                 groups=1,\n",
    "                 bias=True,\n",
    "                 causal=True):\n",
    "        super(Convolution1D, self).__init__(\n",
    "            in_channels, out_channels, kernel_size,\n",
    "            stride=stride, padding=0 if causal else padding,\n",
    "            dilation=dilation, groups=groups, bias=bias)\n",
    "\n",
    "        self.left_pad = dilation * (kernel_size - 1) if causal else 0\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = F.pad(input, (self.left_pad, 0))\n",
    "\n",
    "        return super(Convolution1D, self).forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 2, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 300])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "causalconv1d = Convolution1D(2, 4, 2, causal=True)\n",
    "causalconv1d(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules.utils import _pair\n",
    "\n",
    "class Convolution2D(nn.Conv2d):\n",
    "    \"\"\"2D Convolution (dilated-causal convolution)\"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 in_channels, \n",
    "                 out_channels, \n",
    "                 kernel_size, \n",
    "                 stride=1, \n",
    "                 padding=None, \n",
    "                 dilation=1, \n",
    "                 groups=1, \n",
    "                 bias=True,\n",
    "                 causal=True):\n",
    "        kernel_size = _pair(kernel_size)\n",
    "        stride = _pair(stride)\n",
    "        dilation = _pair(dilation)\n",
    "        if causal:\n",
    "            padding = [int((kernel_size[i]-1) * dilation[i]) for i in range(len(kernel_size))]\n",
    "    \n",
    "        super(Convolution2D, self).__init__(\n",
    "            in_channels, out_channels, kernel_size,\n",
    "            stride=stride, padding=0 if causal else padding, \n",
    "            dilation=dilation, groups=groups, bias=bias)\n",
    "        \n",
    "        self.left_pad = _pair(padding) if causal else _pair(0)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = F.pad(inputs, (self.left_pad[1], 0, self.left_pad[0], 0))\n",
    "\n",
    "        return super(Convolution2D, self).forward(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 2, 192, 600)\n",
    "causalconv2d = Convolution2D(2, 1, 3, 1, causal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 192, 600])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "causalconv2d(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class ConvolutionTranspose2D(nn.ConvTranspose2d):\n",
    "    \"\"\"2D Transposed Convolution (dilated-causal convolution)\"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 in_channels, \n",
    "                 out_channels, \n",
    "                 kernel_size, \n",
    "                 stride=1, \n",
    "                 padding=None,\n",
    "                 dilation=1, \n",
    "                 groups=1, \n",
    "                 bias=True, \n",
    "                 causal=False):\n",
    "        super(ConvolutionTranspose2D, self).__init__(\n",
    "            in_channels, out_channels, kernel_size, stride=stride,\n",
    "            padding=0 if causal else padding,\n",
    "            dilation=dilation, groups=groups, bias=bias)\n",
    "        self.causal = causal\n",
    "        \n",
    "        kh, kw = _pair(kernel_size)\n",
    "        dh, dw = _pair(dilation)\n",
    "        \n",
    "        self.crop_h = (kh - 1) * dh if causal else 0\n",
    "        self.crop_w = (kw - 1) * dw if causal else 0\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x_ = super(ConvolutionTranspose2D, self).forward(x)\n",
    "        \n",
    "        if self.causal:\n",
    "            x_ = x_[:, :, self.crop_h:, self.crop_w:]\n",
    "\n",
    "        h_pad, w_pad = x.shape[2] * self.stride[0] - x_.shape[2], x.shape[3] * self.stride[1] - x_.shape[3]\n",
    "        x_ = F.pad(x_, (0, w_pad, 0, h_pad))\n",
    "        \n",
    "        return x_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 4, 48, 600)\n",
    "causalconvtranspose2d = ConvolutionTranspose2D(4, 2, (5,2), (1,1), causal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 48, 600])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "causalconvtranspose2d(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNNFilter(nn.GRU):\n",
    "\n",
    "    def __init__(self, \n",
    "                 input_size, \n",
    "                 hidden_size,\n",
    "                 num_layers,\n",
    "                 bias=True,\n",
    "                 batch_first=True,\n",
    "                 dropout=0.,\n",
    "                 bidirectional=False,):\n",
    "        super().__init__(input_size, \n",
    "                 hidden_size,\n",
    "                 num_layers,\n",
    "                 bias=bias,\n",
    "                 batch_first=batch_first,\n",
    "                 dropout=dropout,\n",
    "                 bidirectional=bidirectional,)\n",
    "        \n",
    "        # self.num_layers = num_layers\n",
    "        # self.D = 2 if bidirectional else 1\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        output, _ = super().forward(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 600, 8)\n",
    "rnn = RNNFilter(8, 8, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 600, 8])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.tfs import TCM\n",
    "tcm = TCM(8, 16, (1,2,4,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 600])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1, 8, 600)\n",
    "tcm(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Fuse Merge Net\n",
      "Audio Codec 18.0kbps Initialized\n",
      "Quantization Vis: \n",
      "     Freq dims:  [6, 6, 12, 24, 48, 96]\n",
      "     Channel(hidden) dims:  [64, 64, 32, 24, 24, 16]\n",
      "     projections from:  [384, 384, 384, 576, 1152, 1536]\n",
      "     projections to:  [192, 192, 192, 288, 576, 768]\n",
      "     group_vq_dims:  [768, 768, 768, 1152, 2304, 3072]\n"
     ]
    }
   ],
   "source": [
    "from models.codec import ConvCrossScaleCodec\n",
    "\n",
    "model = ConvCrossScaleCodec(fuse_net=True, scalable=True, use_tf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvCrossScaleCodec(\n",
       "  (ft): Spectrogram()\n",
       "  (ift): InverseSpectrogram()\n",
       "  (recon_loss): MSELoss()\n",
       "  (mel_loss): MELLoss(\n",
       "    (mel_transf1): MelSpectrogram(\n",
       "      (spectrogram): Spectrogram()\n",
       "      (mel_scale): MelScale()\n",
       "    )\n",
       "    (mel_transf2): MelSpectrogram(\n",
       "      (spectrogram): Spectrogram()\n",
       "      (mel_scale): MelScale()\n",
       "    )\n",
       "    (mel_transf3): MelSpectrogram(\n",
       "      (spectrogram): Spectrogram()\n",
       "      (mel_scale): MelScale()\n",
       "    )\n",
       "    (mel_transf4): MelSpectrogram(\n",
       "      (spectrogram): Spectrogram()\n",
       "      (mel_scale): MelScale()\n",
       "    )\n",
       "    (mel_transf5): MelSpectrogram(\n",
       "      (spectrogram): Spectrogram()\n",
       "      (mel_scale): MelScale()\n",
       "    )\n",
       "    (mel_transf6): MelSpectrogram(\n",
       "      (spectrogram): Spectrogram()\n",
       "      (mel_scale): MelScale()\n",
       "    )\n",
       "  )\n",
       "  (encoder): ConvEncoder(\n",
       "    (blocks): ModuleList(\n",
       "      (0): ConvEncoderLayer(\n",
       "        (conv): Convolution2D(\n",
       "          (conv): Conv2d(2, 16, kernel_size=(5, 2), stride=(1, 1))\n",
       "        )\n",
       "        (norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (1): ConvEncoderLayer(\n",
       "        (conv): Convolution2D(\n",
       "          (conv): Conv2d(16, 16, kernel_size=(5, 2), stride=(2, 1))\n",
       "        )\n",
       "        (norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (2): ConvEncoderLayer(\n",
       "        (conv): Convolution2D(\n",
       "          (conv): Conv2d(16, 24, kernel_size=(5, 2), stride=(2, 1))\n",
       "        )\n",
       "        (norm): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (3): ConvEncoderLayer(\n",
       "        (conv): Convolution2D(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(5, 2), stride=(2, 1))\n",
       "        )\n",
       "        (norm): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (4): ConvEncoderLayer(\n",
       "        (conv): Convolution2D(\n",
       "          (conv): Conv2d(24, 32, kernel_size=(5, 2), stride=(2, 1))\n",
       "        )\n",
       "        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (5): ConvEncoderLayer(\n",
       "        (conv): Convolution2D(\n",
       "          (conv): Conv2d(32, 64, kernel_size=(5, 2), stride=(2, 1))\n",
       "        )\n",
       "        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=1)\n",
       "      )\n",
       "    )\n",
       "    (temp_filter1): TCM(\n",
       "      (block): Sequential(\n",
       "        (0): TCNNResBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Convolution1D(\n",
       "              (conv): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (1): PReLU(num_parameters=1)\n",
       "            (2): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): DConv1d(\n",
       "              (conv): Conv1d(768, 768, kernel_size=(5,), stride=(1,), padding=(4,), groups=768, bias=False)\n",
       "            )\n",
       "            (4): PReLU(num_parameters=1)\n",
       "            (5): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (6): Convolution1D(\n",
       "              (conv): Conv1d(768, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): TCNNResBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Convolution1D(\n",
       "              (conv): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (1): PReLU(num_parameters=1)\n",
       "            (2): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): DConv1d(\n",
       "              (conv): Conv1d(768, 768, kernel_size=(5,), stride=(1,), padding=(8,), dilation=(2,), groups=768, bias=False)\n",
       "            )\n",
       "            (4): PReLU(num_parameters=1)\n",
       "            (5): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (6): Convolution1D(\n",
       "              (conv): Conv1d(768, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): TCNNResBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Convolution1D(\n",
       "              (conv): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (1): PReLU(num_parameters=1)\n",
       "            (2): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): DConv1d(\n",
       "              (conv): Conv1d(768, 768, kernel_size=(5,), stride=(1,), padding=(16,), dilation=(4,), groups=768, bias=False)\n",
       "            )\n",
       "            (4): PReLU(num_parameters=1)\n",
       "            (5): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (6): Convolution1D(\n",
       "              (conv): Conv1d(768, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): TCNNResBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Convolution1D(\n",
       "              (conv): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (1): PReLU(num_parameters=1)\n",
       "            (2): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): DConv1d(\n",
       "              (conv): Conv1d(768, 768, kernel_size=(5,), stride=(1,), padding=(32,), dilation=(8,), groups=768, bias=False)\n",
       "            )\n",
       "            (4): PReLU(num_parameters=1)\n",
       "            (5): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (6): Convolution1D(\n",
       "              (conv): Conv1d(768, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (temp_filter2): RNNFilter(384, 384, batch_first=True)\n",
       "  )\n",
       "  (decoder): ConvCrossScaleDecoder(\n",
       "    (blocks): ModuleList(\n",
       "      (0): ConvDecoderLayer(\n",
       "        (conv): ConvolutionTranspose2D(\n",
       "          (conv): ConvTranspose2d(64, 32, kernel_size=(5, 2), stride=(2, 1))\n",
       "        )\n",
       "        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (1): ConvDecoderLayer(\n",
       "        (conv): ConvolutionTranspose2D(\n",
       "          (conv): ConvTranspose2d(32, 24, kernel_size=(5, 2), stride=(2, 1))\n",
       "        )\n",
       "        (norm): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (2): ConvDecoderLayer(\n",
       "        (conv): ConvolutionTranspose2D(\n",
       "          (conv): ConvTranspose2d(24, 24, kernel_size=(5, 2), stride=(2, 1))\n",
       "        )\n",
       "        (norm): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (3): ConvDecoderLayer(\n",
       "        (conv): ConvolutionTranspose2D(\n",
       "          (conv): ConvTranspose2d(24, 16, kernel_size=(5, 2), stride=(2, 1))\n",
       "        )\n",
       "        (norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (4): ConvDecoderLayer(\n",
       "        (conv): ConvolutionTranspose2D(\n",
       "          (conv): ConvTranspose2d(16, 16, kernel_size=(5, 2), stride=(2, 1))\n",
       "        )\n",
       "        (norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=1)\n",
       "      )\n",
       "      (5): ConvDecoderLayer(\n",
       "        (conv): ConvolutionTranspose2D(\n",
       "          (conv): ConvTranspose2d(16, 2, kernel_size=(5, 2), stride=(1, 1))\n",
       "        )\n",
       "        (norm): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): PReLU(num_parameters=1)\n",
       "      )\n",
       "    )\n",
       "    (temp_filter1): TCM(\n",
       "      (block): Sequential(\n",
       "        (0): TCNNResBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Convolution1D(\n",
       "              (conv): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (1): PReLU(num_parameters=1)\n",
       "            (2): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): DConv1d(\n",
       "              (conv): Conv1d(768, 768, kernel_size=(5,), stride=(1,), padding=(4,), groups=768, bias=False)\n",
       "            )\n",
       "            (4): PReLU(num_parameters=1)\n",
       "            (5): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (6): Convolution1D(\n",
       "              (conv): Conv1d(768, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): TCNNResBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Convolution1D(\n",
       "              (conv): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (1): PReLU(num_parameters=1)\n",
       "            (2): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): DConv1d(\n",
       "              (conv): Conv1d(768, 768, kernel_size=(5,), stride=(1,), padding=(8,), dilation=(2,), groups=768, bias=False)\n",
       "            )\n",
       "            (4): PReLU(num_parameters=1)\n",
       "            (5): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (6): Convolution1D(\n",
       "              (conv): Conv1d(768, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): TCNNResBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Convolution1D(\n",
       "              (conv): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (1): PReLU(num_parameters=1)\n",
       "            (2): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): DConv1d(\n",
       "              (conv): Conv1d(768, 768, kernel_size=(5,), stride=(1,), padding=(16,), dilation=(4,), groups=768, bias=False)\n",
       "            )\n",
       "            (4): PReLU(num_parameters=1)\n",
       "            (5): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (6): Convolution1D(\n",
       "              (conv): Conv1d(768, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): TCNNResBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Convolution1D(\n",
       "              (conv): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (1): PReLU(num_parameters=1)\n",
       "            (2): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): DConv1d(\n",
       "              (conv): Conv1d(768, 768, kernel_size=(5,), stride=(1,), padding=(32,), dilation=(8,), groups=768, bias=False)\n",
       "            )\n",
       "            (4): PReLU(num_parameters=1)\n",
       "            (5): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (6): Convolution1D(\n",
       "              (conv): Conv1d(768, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (temp_filter2): RNNFilter(384, 384, batch_first=True)\n",
       "    (temp_filter3): TCM(\n",
       "      (block): Sequential(\n",
       "        (0): TCNNResBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Convolution1D(\n",
       "              (conv): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (1): PReLU(num_parameters=1)\n",
       "            (2): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): DConv1d(\n",
       "              (conv): Conv1d(768, 768, kernel_size=(5,), stride=(1,), padding=(4,), groups=768, bias=False)\n",
       "            )\n",
       "            (4): PReLU(num_parameters=1)\n",
       "            (5): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (6): Convolution1D(\n",
       "              (conv): Conv1d(768, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): TCNNResBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Convolution1D(\n",
       "              (conv): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (1): PReLU(num_parameters=1)\n",
       "            (2): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): DConv1d(\n",
       "              (conv): Conv1d(768, 768, kernel_size=(5,), stride=(1,), padding=(8,), dilation=(2,), groups=768, bias=False)\n",
       "            )\n",
       "            (4): PReLU(num_parameters=1)\n",
       "            (5): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (6): Convolution1D(\n",
       "              (conv): Conv1d(768, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): TCNNResBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Convolution1D(\n",
       "              (conv): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (1): PReLU(num_parameters=1)\n",
       "            (2): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): DConv1d(\n",
       "              (conv): Conv1d(768, 768, kernel_size=(5,), stride=(1,), padding=(16,), dilation=(4,), groups=768, bias=False)\n",
       "            )\n",
       "            (4): PReLU(num_parameters=1)\n",
       "            (5): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (6): Convolution1D(\n",
       "              (conv): Conv1d(768, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): TCNNResBlock(\n",
       "          (block): Sequential(\n",
       "            (0): Convolution1D(\n",
       "              (conv): Conv1d(384, 768, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "            (1): PReLU(num_parameters=1)\n",
       "            (2): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): DConv1d(\n",
       "              (conv): Conv1d(768, 768, kernel_size=(5,), stride=(1,), padding=(32,), dilation=(8,), groups=768, bias=False)\n",
       "            )\n",
       "            (4): PReLU(num_parameters=1)\n",
       "            (5): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (6): Convolution1D(\n",
       "              (conv): Conv1d(768, 384, kernel_size=(1,), stride=(1,))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pre_fuse_net): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Convolution2D(\n",
       "          (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "        )\n",
       "        (1): Convolution2D(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Convolution2D(\n",
       "          (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "        )\n",
       "        (1): Convolution2D(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (2-3): 2 x Sequential(\n",
       "        (0): Convolution2D(\n",
       "          (conv): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1))\n",
       "        )\n",
       "        (1): Convolution2D(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): Convolution2D(\n",
       "          (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "        )\n",
       "        (1): Convolution2D(\n",
       "          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (post_fuse_net): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Convolution2D(\n",
       "          (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "        )\n",
       "        (1): Convolution2D(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Convolution2D(\n",
       "          (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "        )\n",
       "        (1): Convolution2D(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (2-3): 2 x Sequential(\n",
       "        (0): Convolution2D(\n",
       "          (conv): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1))\n",
       "        )\n",
       "        (1): Convolution2D(\n",
       "          (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): Convolution2D(\n",
       "          (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "        )\n",
       "        (1): Convolution2D(\n",
       "          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (quantizer): ModuleList(\n",
       "    (0-2): 3 x GroupVQ(\n",
       "      (proj_down): Linear(in_features=384, out_features=192, bias=False)\n",
       "      (proj_up): Linear(in_features=192, out_features=384, bias=False)\n",
       "      (vqs): ModuleList(\n",
       "        (0-5): 6 x VectorQuantization()\n",
       "      )\n",
       "    )\n",
       "    (3): GroupVQ(\n",
       "      (proj_down): Linear(in_features=576, out_features=288, bias=False)\n",
       "      (proj_up): Linear(in_features=288, out_features=576, bias=False)\n",
       "      (vqs): ModuleList(\n",
       "        (0-5): 6 x VectorQuantization()\n",
       "      )\n",
       "    )\n",
       "    (4): GroupVQ(\n",
       "      (proj_down): Linear(in_features=1152, out_features=576, bias=False)\n",
       "      (proj_up): Linear(in_features=576, out_features=1152, bias=False)\n",
       "      (vqs): ModuleList(\n",
       "        (0-5): 6 x VectorQuantization()\n",
       "      )\n",
       "    )\n",
       "    (5): GroupVQ(\n",
       "      (proj_down): Linear(in_features=1536, out_features=768, bias=False)\n",
       "      (proj_up): Linear(in_features=768, out_features=1536, bias=False)\n",
       "      (vqs): ModuleList(\n",
       "        (0-5): 6 x VectorQuantization()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timm.models.layers import trunc_normal_, to_2tuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "class WindowAttention(nn.Module):\n",
    "    def __init__(self, dim, window_size, num_heads, qkv_bias=True, qk_scale=None, attn_drop=0., proj_drop=0.):\n",
    "\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.window_size = window_size  # Wh, Ww\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "\n",
    "        # define a parameter table of relative position bias\n",
    "        self.relative_position_bias_table = nn.Parameter(\n",
    "            torch.zeros((2 * window_size[0] - 1) * (2 * window_size[1] - 1), num_heads))  # 2*Wh-1 * 2*Ww-1, nH\n",
    "\n",
    "        # get pair-wise relative position index for each token inside the window\n",
    "        coords_h = torch.arange(self.window_size[0])\n",
    "        coords_w = torch.arange(self.window_size[1])\n",
    "        coords = torch.stack(torch.meshgrid([coords_h, coords_w]))  # 2, Wh, Ww\n",
    "        coords_flatten = torch.flatten(coords, 1)  # 2, Wh*Ww\n",
    "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]  # 2, Wh*Ww, Wh*Ww\n",
    "        relative_coords = relative_coords.permute(1, 2, 0).contiguous()  # Wh*Ww, Wh*Ww, 2\n",
    "        relative_coords[:, :, 0] += self.window_size[0] - 1  # shift to start from 0\n",
    "        relative_coords[:, :, 1] += self.window_size[1] - 1\n",
    "        relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n",
    "        relative_position_index = relative_coords.sum(-1)  # Wh*Ww, Wh*Ww\n",
    "        self.register_buffer(\"relative_position_index\", relative_position_index)\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "        trunc_normal_(self.relative_position_bias_table, std=.02)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        \"\"\" Forward function.\n",
    "        Args:\n",
    "            x: input features with shape of (num_windows*B, N, C)\n",
    "            mask: (0/-inf) mask with shape of (num_windows, Wh*Ww, Wh*Ww) or None\n",
    "        \"\"\"\n",
    "        B_, N, C = x.shape\n",
    "        qkv = self.qkv(x).reshape(B_, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4).contiguous()\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]  # make torchscript happy (cannot use tensor as tuple)\n",
    "        print(\"q k v shape: \", q.shape, k.shape, v.shape)\n",
    "        q = q * self.scale\n",
    "        attn = (q @ k.transpose(-2, -1))\n",
    "        print(\"attn q@k shape: \", attn.shape)\n",
    "        \n",
    "        relative_position_bias = self.relative_position_bias_table[self.relative_position_index.view(-1)].view(\n",
    "            self.window_size[0] * self.window_size[1], self.window_size[0] * self.window_size[1], -1)  # Wh*Ww,Wh*Ww,nH\n",
    "        relative_position_bias = relative_position_bias.permute(2, 0, 1).contiguous()  # nH, Wh*Ww, Wh*Ww\n",
    "        attn = attn + relative_position_bias.unsqueeze(0)\n",
    "\n",
    "        if mask is not None:\n",
    "            nW = mask.shape[0]\n",
    "            attn = attn.view(B_ // nW, nW, self.num_heads, N, N) + mask.unsqueeze(1).unsqueeze(0)\n",
    "            attn = attn.view(-1, self.num_heads, N, N)\n",
    "            print(\"adding mask: \", attn)\n",
    "            attn = self.softmax(attn)\n",
    "            print(\"after softmax: \", attn)\n",
    "\n",
    "        else:\n",
    "            attn = self.softmax(attn)\n",
    "\n",
    "        attn = self.attn_drop(attn)\n",
    "        print(\"attn_dist: \", attn)\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B_, N, C)\n",
    "        print(\"attn_out: \", x)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 3\n",
    "window_size = 2\n",
    "num_heads = 1\n",
    "\n",
    "attn = WindowAttention(d_model, window_size=to_2tuple(window_size), num_heads=num_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., -inf, -inf, -inf],\n",
       "         [0., 0., -inf, -inf],\n",
       "         [0., 0., 0., -inf],\n",
       "         [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_causal_mask_for_windows(num_windows, window_size):\n",
    "    \"\"\"\n",
    "    Create a causal mask for a given number of windows and window size.\n",
    "    \n",
    "    Args:\n",
    "        num_windows (int): The number of windows for which the mask is to be created.\n",
    "        window_size (int): The size of each window.\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: A causal mask of shape (num_windows, window_size * window_size, window_size * window_size).\n",
    "    \"\"\"\n",
    "    single_window_mask = torch.triu(torch.full((window_size * window_size, window_size * window_size), float('-inf')), diagonal=1)\n",
    "    mask = single_window_mask.unsqueeze(0).repeat(num_windows, 1, 1)\n",
    "    return mask\n",
    "\n",
    "num_windows = 1\n",
    "causal_mask = create_causal_mask_for_windows(num_windows, window_size)\n",
    "causal_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 3])\n",
      "q k v shape:  torch.Size([1, 1, 4, 3]) torch.Size([1, 1, 4, 3]) torch.Size([1, 1, 4, 3])\n",
      "attn q@k shape:  torch.Size([1, 1, 4, 4])\n",
      "attn_dist:  tensor([[[[0.4157, 0.0918, 0.0954, 0.3972],\n",
      "          [0.3914, 0.0856, 0.0759, 0.4471],\n",
      "          [0.3792, 0.1426, 0.1625, 0.3156],\n",
      "          [0.3711, 0.0644, 0.0543, 0.5101]]]], grad_fn=<SoftmaxBackward0>)\n",
      "attn_out:  tensor([[[-1.6874,  0.9687,  1.0449],\n",
      "         [-1.7257,  0.9954,  1.0435],\n",
      "         [-1.6834,  1.0428,  1.0451],\n",
      "         [-1.7572,  1.0056,  1.0389]]], grad_fn=<ReshapeAliasBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5366,  1.9465,  0.9556],\n",
       "         [-0.5383,  1.9671,  0.9580],\n",
       "         [-0.5156,  1.9583,  0.9194],\n",
       "         [-0.5417,  1.9801,  0.9638]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 1\n",
    "\n",
    "x = torch.ones(bs*num_windows, window_size*window_size, d_model)\n",
    "x = torch.Tensor([[[1,2,3],\n",
    "                   [4,3,1],\n",
    "                   [2,1,1],\n",
    "                   [3,4,2]]])\n",
    "print(x.shape)\n",
    "attn_out = attn(x)\n",
    "attn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q k v shape:  torch.Size([1, 1, 4, 3]) torch.Size([1, 1, 4, 3]) torch.Size([1, 1, 4, 3])\n",
      "attn q@k shape:  torch.Size([1, 1, 4, 4])\n",
      "adding mask:  tensor([[[[ 1.4206,    -inf,    -inf,    -inf],\n",
      "          [ 1.4375, -0.0829,    -inf,    -inf],\n",
      "          [ 0.9014, -0.0769,  0.0541,    -inf],\n",
      "          [ 1.6335, -0.1172, -0.2888,  1.9517]]]], grad_fn=<ViewBackward0>)\n",
      "after softmax:  tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.8206, 0.1794, 0.0000, 0.0000],\n",
      "          [0.5542, 0.2083, 0.2375, 0.0000],\n",
      "          [0.3711, 0.0644, 0.0543, 0.5101]]]], grad_fn=<SoftmaxBackward0>)\n",
      "attn_dist:  tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.8206, 0.1794, 0.0000, 0.0000],\n",
      "          [0.5542, 0.2083, 0.2375, 0.0000],\n",
      "          [0.3711, 0.0644, 0.0543, 0.5101]]]], grad_fn=<SoftmaxBackward0>)\n",
      "attn_out:  tensor([[[-1.1582,  0.2155,  1.0944],\n",
      "         [-1.3923,  0.5742,  1.1232],\n",
      "         [-1.4680,  0.8772,  1.0700],\n",
      "         [-1.7572,  1.0056,  1.0389]]], grad_fn=<ReshapeAliasBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6273,  1.6082,  1.1172],\n",
       "         [-0.5991,  1.7889,  1.0587],\n",
       "         [-0.5160,  1.8484,  0.9215],\n",
       "         [-0.5417,  1.9801,  0.9638]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_out = attn(x, causal_mask)\n",
    "attn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
