{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 10:21:09.021023: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import dac\n",
    "# from audiotools import AudioSignal\n",
    "\n",
    "model_path = dac.utils.download(model_type=\"16khz\")\n",
    "model = dac.DAC.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResidualVectorQuantize(\n",
       "  (quantizers): ModuleList(\n",
       "    (0-11): 12 x VectorQuantize(\n",
       "      (in_proj): Conv1d(1024, 8, kernel_size=(1,), stride=(1,))\n",
       "      (out_proj): Conv1d(8, 1024, kernel_size=(1,), stride=(1,))\n",
       "      (codebook): Embedding(1024, 8)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.quantizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1158, 160000])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pesq import pesq\n",
    "\n",
    "testset = torch.load(\"./data/DNS_CHALLENGE/processed_yz/test.pt\")\n",
    "testset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating DAC at 6.00kbps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1158/1158 [11:15<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test PESQ:  4.01297817380523\n",
      "Evaluating DAC at 4.50kbps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1158/1158 [11:03<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test PESQ:  3.5776374306085814\n",
      "Evaluating DAC at 3.00kbps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1158/1158 [11:00<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test PESQ:  3.0323141937497433\n",
      "Evaluating DAC at 1.50kbps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1158/1158 [11:44<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test PESQ:  2.588869664284026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "SR = 16000\n",
    "n_quantizers = 12\n",
    "\n",
    "device = \"cuda\"\n",
    "model = model.to(device)\n",
    "\n",
    "test_perf = []\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    for n_q in [12, 9, 6, 3]:\n",
    "        print(f\"Evaluating DAC at {n_q*.5:.2f}kbps\")\n",
    "        for i in tqdm(range(testset.size(0))):\n",
    "            x = testset[i:i+1, :-80].unsqueeze(1).to(device)\n",
    "            x_process = model.preprocess(x, sample_rate=SR)\n",
    "\n",
    "            z, codes, latents, _, _ = model.encode(x_process, n_quantizers=n_q)\n",
    "            x_recon = model.decode(z)\n",
    "\n",
    "            obj_score = pesq(SR, \n",
    "                             x.squeeze(0).squeeze(0).cpu().numpy(), \n",
    "                             x_recon.squeeze(0).squeeze(0).cpu().numpy(), 'wb')\n",
    "            test_perf.append(obj_score)\n",
    "        print(\"Test PESQ: \", np.mean(test_perf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1024, 499]),\n",
       " torch.Size([1, 12, 499]),\n",
       " torch.Size([1, 96, 499]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape, codes.shape, latents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18000.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10 * 36 * 500 / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10 * 12 * 500 / 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
